{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните следующие шаги:\n",
    "\n",
    "1) Скачайте файл с предложениями (sentences.txt).\n",
    "2) Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower().\n",
    "3) Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения.\n",
    "4) Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict.\n",
    "5) Создайте матрицу размера n * d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254.\n",
    "6) Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание. Само предложение (In comparison to dogs, cats have not undergone... ) имеет индекс 0.\n",
    "7) Запишите полученные числа в файл, разделив пробелом. Обратите внимание, что файл должен состоять из одной строки, в конце которой не должно быть переноса. Пример файла с решением вы можете найти в конце задания (submission-1.txt).\n",
    "8) Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "\n",
    "Разумеется, использованный вами метод крайне простой. Например, он не учитывает формы слов (так, cat и cats он считает разными словами, хотя по сути они означают одно и то же), не удаляет из текстов артикли и прочие ненужные слова. Позже мы будем подробно изучать анализ текстов, где выясним, как достичь высокого качества в задаче поиска похожих предложений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "ex_sents = []\n",
    "with open('sentences.txt', 'r') as file:\n",
    "    for element in file:\n",
    "        buffer = element.lower()\n",
    "        buffer = re.split('[^a-z]', buffer)\n",
    "        ex_sents.append(buffer)\n",
    "        sc_buffer = []\n",
    "        for element in buffer:\n",
    "            if len(element) != 0:\n",
    "                sc_buffer.append(element)\n",
    "        sents.append(sc_buffer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indict = {}\n",
    "counter = 1\n",
    "for line in sents:\n",
    "    for element in line:\n",
    "        if element in indict:\n",
    "            pass\n",
    "        else:\n",
    "            indict[element] = counter\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdict = {}\n",
    "for line in sents:\n",
    "    for element in line:\n",
    "        if element in ctdict:\n",
    "            ctdict[element] = ctdict[element] + 1\n",
    "        else:\n",
    "            ctdict[element] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for line in range(len(ex_sents)):\n",
    "    buff = []\n",
    "    for element in indict:\n",
    "        buff.append(ex_sents[line].count(element))\n",
    "    matrix.append(buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 254)\n",
      "My matrix:\n",
      " [[1 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "wordmatrix = np.array(matrix)\n",
    "print(wordmatrix.shape)\n",
    "print('My matrix:\\n', wordmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.9527544408738466, 0.8644738145642124, 0.8951715163278082, 0.7770887149698589, 0.9402385695332803, 0.7327387580875756, 0.9258750683338899, 0.8842724875284311, 0.9055088817476932, 0.8328165362273942, 0.8804771390665607, 0.8396432548525454, 0.8703592552895671, 0.8740118423302576, 0.9442721787424647, 0.8406361854220809, 0.956644501523794, 0.9442721787424647, 0.8885443574849294, 0.8427572744917122, 0.8250364469440588]\n"
     ]
    }
   ],
   "source": [
    "cosinrange = []\n",
    "for i in range(len(ex_sents)):\n",
    "    cosinrange.append((scipy.spatial.distance.cosine(wordmatrix[0,:], wordmatrix[i,:])))\n",
    "print(cosinrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (6, 0.7327387580875756), (4, 0.7770887149698589), (21, 0.8250364469440588), (10, 0.8328165362273942), (12, 0.8396432548525454), (16, 0.8406361854220809), (20, 0.8427572744917122), (2, 0.8644738145642124), (13, 0.8703592552895671), (14, 0.8740118423302576), (11, 0.8804771390665607), (8, 0.8842724875284311), (19, 0.8885443574849294), (3, 0.8951715163278082), (9, 0.9055088817476932), (7, 0.9258750683338899), (5, 0.9402385695332803), (15, 0.9442721787424647), (18, 0.9442721787424647), (1, 0.9527544408738466), (17, 0.956644501523794)]\n"
     ]
    }
   ],
   "source": [
    "rangedict = {}\n",
    "for i in range(len(cosinrange)):\n",
    "    rangedict[i] = cosinrange[i]\n",
    "    \n",
    "rangedict = sorted(rangedict.items(), key=lambda x: x[1], reverse=False)\n",
    "print(rangedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission-1.txt', 'w') as fh:\n",
    "    fh.write('{} {}'.format(rangedict[1][0], rangedict[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
